{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustements de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chute libre\n",
    "\n",
    "Des étudiants ont effectué une expérience de chute libre : ils ont fait tomber un objet de chaque étage de l'Atrium, sans vitesse initiale, et ont mesuré à chaque fois le temps de chute $T$ de l'objet ainsi que la hauteur de l'étage $H$. On reporte dans le tableau ci-dessous le résultat des mesures pour 4 groupes différents.\n",
    "\n",
    "![data chute libre](./table_analyse_chute.png)\n",
    "\n",
    "Nous savons que l'objet chute sous l'effet de la pesanteur. Nous voulons grâce à cette expérience déterminer la magnitude de la pesanteur. Pour cela, nous utilisons un modèle simple du temps de chute libre. On montre facilement d'après la loi fondamentale de la dynamique, si on néglige les frottements de l'air, le lien entre la hauteur de l'étage $H$, le temps de chute $T$, et la magnitude de la pesanteur $g$ :\n",
    "\n",
    "$$\n",
    "H = g\\times\\dfrac{T^2}{2}\n",
    "$$\n",
    "\n",
    "1. Identifier dans cette équation  le(s) donnée(s) de l'expérience et le(s) paramètre(s) du modèle. Écrire les données sous la forme de tableaux numpy.\n",
    "2. Écrire le modèle sous la forme d'une fonction python à ajuster, de la forme $y(x;a)=ax$.\n",
    "3. Déterminer la valeur de $g$ en ajustant les données du 1er groupe. Afficher à l'écran la valeur trouvée, et faire un graphique sur lequel on voit le modèle (en ligne continue) et les données (marqueurs). On veillera à légender et mettre des titres aux axes et au graphique.\n",
    "4. Ajuster les données des 4 groupes grâce à une boucle, et calculer la valeur de $g$ comme la moyenne des résultats des 4 groupes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1\n",
    "# H et T sont les données de l'expérience\n",
    "# g est un paramètre du modèle\n",
    "\n",
    "# Écriture des données dans un tableau numpy\n",
    "T = np.array([[1.09,  1.39,  1.70,  2.05,  2.25],\n",
    "              [1.17,  1.54,  1.72,  2.18,  2.40],\n",
    "              [1.33,  1.68,  1.56,  2.19,  2.40],\n",
    "              [0.95,  1.61,  1.49,  2.16,  2.18]])\n",
    "H = np.array([7.40,  10.80, 14.20, 17.60, 20.95])\n",
    "\n",
    "#2\n",
    "# Modèle\n",
    "def chute(x, a):\n",
    "    return a * x\n",
    "\n",
    "#3\n",
    "# Ajustement des données du 1er groupe\n",
    "y = H\n",
    "x = T[0, :] ** 2 / 2\n",
    "params, covar = curve_fit(chute, x, y)\n",
    "# Affichage de la valeur trouvée\n",
    "print(\"Groupe 1 :\")\n",
    "print(\"  g = \", params[0], \" m/s^2\")\n",
    "\n",
    "# Graphique\n",
    "xm = np.linspace(0, 3, 100)\n",
    "plt.plot(xm, chute(xm, params[0]))\n",
    "plt.plot(x, y, '*')\n",
    "plt.axis([0, 3, 0, 25])\n",
    "plt.legend(('Modèle', 'Données'))\n",
    "plt.title('Ajustement des données du groupe 1')\n",
    "plt.xlabel('T**2/2 [s**2]')\n",
    "plt.ylabel('H [m]')\n",
    "plt.show()\n",
    "\n",
    "#4\n",
    "# Ajustement des données de tous les groupes\n",
    "Ng = 4\n",
    "g = np.empty(4)\n",
    "for i in range(4):\n",
    "    # Ajustement des données du ième groupe\n",
    "    y = H\n",
    "    x = T[i, :] ** 2 / 2\n",
    "    params, covar = curve_fit(chute, x, y)\n",
    "    # Affichage de la valeur trouvée\n",
    "    print(\"Groupe\", str(i + 1), \":\")\n",
    "    print(\"  g =\", params[0], \"m/s^2\")\n",
    "    g[i] = params[0]\n",
    "    # Graphique\n",
    "    plt.plot(xm, chute(xm, params[0]), label = \"Groupe \" + str(i) + \", modèle\")\n",
    "    plt.plot(x, y, '*', label = \"Groupe \" + str(i) + \", expérience\")\n",
    "plt.axis([0, 3, 0, 25])\n",
    "plt.legend(bbox_to_anchor = (1.05, 1.0))\n",
    "plt.title('Ajustement des données du groupe 1')\n",
    "plt.xlabel('T**2/2 [s**2]')\n",
    "plt.ylabel('H [m]')\n",
    "plt.show()\n",
    "# Affichage de la valeur moyenne\n",
    "print(\"Valeur Moyenne :\")\n",
    "print(\"  g =\", np.mean(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loi de puissance\n",
    "On va travailler sur les données des exoplanètes. Le but de l'exercice consiste à déterminer si les données expérimentales peuvent être ajustées par la fonction correspondant à la 3ème loi de Kepler.\n",
    "\n",
    "1. Charger les données des exoplanètes du fichier `exoplanets.dat` et representer $\\log(R)$ en fonction de $\\log(T)$\n",
    "2. Expliquer pourquoi la représentation graphique logarithmique est mieux adaptée que la représentation graphique linéaire.\n",
    "3. Montrer également (par le calcul) qu'il est possible de faire une régression linéaire en utilisant la représentation mathématique logarithmique pour ajuster la 3ème loi de Kepler.\n",
    "4. Effectuer la régression linéaire sur la troisième loi de Kepler, et comparer la valeur théorique du rapport des exposants $3/2$ à la valeur expérimentale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#1\n",
    "# Importation des librairies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Constantes\n",
    "au = 149597870700.0\n",
    "jour = 24 * 3600\n",
    "\n",
    "# Chargement et conversion des données\n",
    "d_exp = np.loadtxt('./exoplanets.dat')\n",
    "R = d_exp[:, 0] * au\n",
    "T = d_exp[:, 1] * jour\n",
    "\n",
    "# Affichage des données\n",
    "lR = np.log(R)\n",
    "lT = np.log(T)\n",
    "plt.plot(lR, lT, '.')\n",
    "plt.xlabel(\"$\\log(R)$\")\n",
    "plt.ylabel(\"$\\log(T)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**Question 2**\n",
    "L'échelle logarithmique permet de voir toutes les données dispersées sur plusieurs ordres de grandeur.\n",
    "\n",
    "**Question 3**\n",
    "De plus, si $T^2 = K R^3$, alors $\\log(T) = \\frac{3}{2} \\log(R) + \\frac{1}{2} \\log(K)$ \n",
    "\n",
    "==> On peut également tester la relation de proportionalité *via* un ajustement affine des distributions logarithmiques. On attend alors une pente de $1.5$ et une ordonnée à l'origine égale à $0.5\\mathrm{log}(K)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "# Modèle\n",
    "def line(x, a, b):\n",
    "    \"\"\" Loi linéaire \"\"\"\n",
    "    return a * x + b\n",
    "\n",
    "# Ajustement linéaire avec la fonction `line`\n",
    "a, b = curve_fit(line, lR, lT)[0]\n",
    "\n",
    "# Affichage des résultats\n",
    "print('a =', a, '; b = ', b)\n",
    "k = np.exp(2 * b)\n",
    "print(\"K =\", k, \"s^2/m^3\")\n",
    "\n",
    "# Calcul du modèle\n",
    "x = np.linspace(min(lR), max(lR))\n",
    "y = a * x + b\n",
    "\n",
    "# Affichage graphique des résultats\n",
    "plt.plot(lR, lT, '.', label = 'données expérimentales')\n",
    "plt.plot(x, y, label = 'modèle')\n",
    "plt.title('Ajustement du modèle aux données')\n",
    "plt.xlabel(\"$\\log(R)$\")\n",
    "plt.ylabel(\"$\\log(T)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décroissance exponentielle\n",
    "\n",
    "On va ici tenter de modéliser la vitesse de décroissance de l'épaisseur de mousse de bière. On reprendra pour cela les données présentées par Arnd Leike, chercheur à l'Université Ludwig Maximilians de Munich, dans une publication  qui lui a valu le prix Ig Nobel en 2002.\n",
    "\n",
    "![data beer](./tableau_article_beer.png)\n",
    "\n",
    "1. Représentez le logarithme décimal de l'épaisseur de mousse de la Augustinerbräu en fonction du temps : $\\log_{10}(h) = f(t)$. \n",
    "\n",
    "2. Effectuez l'ajustement qui vous semble le plus approprié, et en déduire le modèle de décroissance auquel cet ajustement correspond. Déterminez le  temps caractéristique de la décroissance.\n",
    "\n",
    "3. Effectuez un ajustement exponentiel de la fonction $h(t)$ (cf résultat ci-dessous), et comparez vos résultats à ceux de la question précédente.\n",
    "\n",
    "4. Le taux de désintégration d'un matériau radioactif suit également une loi exponentielle. Peut-on trouver une analogie avec l'épaisseur de la mousse de bière  ?\n",
    "\n",
    "Dans le tableau 1 de l'article de Leike, l'auteur a également associé des incertitudes aux mesures d'épaisseur de mousses. \n",
    "\n",
    "5. Représentez ces incertitudes graphiquement en utilisant la fonction `errorbar` de matplotlib.\n",
    "\n",
    "6. Reprendre la question 3 en passant les erreurs $\\sigma_{y_i}$ dans le paramètre *sigma* de la fonction `curve_fit`. On veillera à remplacer les valeurs d'incertitudes nulles par une valeur > 0 pour permettre la convergence de l'ajustement (cf équation de la somme S pondérée dans le cours).\n",
    "\n",
    "On pourra remarquer qu'en plus des paramètres ajustés, un 2ème paramètre est retourné par la fonction `curve_fit`. Il s'agit de la matrice de covariance de ces paramètres (que l'on peut noter `pcov`, dont on peut extraire l'incertitude sur chacun des paramètres, donnée par  `perr = np.sqrt(np.diag(pcov))`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "# Données\n",
    "h = np.array([14.0, 11.8, 10.5, 9.3, 8.5, 7.7, 7.1, 6.5, 6.0, 5.3, 4.4, 3.5, 2.9, 1.3, 0.7]) # cm\n",
    "t = np.array([0, 15, 30, 45, 60, 75, 90, 105, 120, 150, 180, 210, 240, 300, 360]) # s\n",
    "lh = np.log(h)\n",
    "\n",
    "# Affichage graphique des données\n",
    "plt.plot(t, lh, '+')\n",
    "plt.xlabel('Temps (s)')\n",
    "plt.ylabel('$\\log(h)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "def modlin(x, a, b):\n",
    "    \"\"\" Loi linéaire \"\"\"\n",
    "    return a + b * x\n",
    "\n",
    "# Ajustement linéaire\n",
    "params, covar = curve_fit(modlin, t, lh, [14, -1])\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"(a, b) =\", params)\n",
    "print(\"tau =\", -1 / params[1], \"s\")\n",
    "\n",
    "# Calcul du modèle\n",
    "t_model = np.linspace(min(t), max(t))\n",
    "y_model = params[0] + params[1] * t_model\n",
    "\n",
    "# Affichage graphique des résultats\n",
    "plt.plot(t, lh, '.', label = 'données expérimentales')\n",
    "plt.plot(t_model, y_model, label = 'modèle')\n",
    "plt.title('Ajustement linéaire du modèle aux données')\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$\\ln(h)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "def expLaw(x, A0, tau):\n",
    "    \"\"\" Loi exponentielle \"\"\"\n",
    "    return A0 * np.exp(-x / tau)\n",
    "\n",
    "# Ajustement exponentiel\n",
    "params, covar = curve_fit(expLaw, t, h, [14, 200])\n",
    "\n",
    "# Affichage des résultats\n",
    "print(params)\n",
    "print(\"tau =\",params[1], \"s\")\n",
    "\n",
    "# Calcul du modèle\n",
    "t_model = np.linspace(min(t), max(t))\n",
    "y_model = params[0] * np.exp(-t_model / params[1])\n",
    "\n",
    "# Affichage graphique des résultats\n",
    "plt.plot(t, h, '.', label = 'données expérimentales')\n",
    "plt.plot(t_model, y_model, label = 'modèle')\n",
    "plt.title('Ajustement exponentiel du modèle aux données')\n",
    "plt.xlabel(\"$t~\\mathrm{(s)}$\")\n",
    "plt.ylabel(\"$h~\\mathrm{(cm)}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "On remarquera que l'ajustements linéaire de $\\mathrm{log}(h)$ et l'ajustement exponentiel de $h$ produisent des valeurs différentes de la constante de temps $\\tau$ caractéristique de la décroissance définie par $y = A_0 e^{-\\frac{t}{\\tau}}$ : $131 \\mathrm{~s}$ contre $148 \\mathrm{~s}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**Question 4**\n",
    "\n",
    "L'évolution des deux phénomènes est modélisée par un phénomène sans mémoire (la désintégration des noyaux radioactifs ou l'éclatement des bulles). La loi est donc exponentielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "dh = np.array([0.01, 0.3, 0.3, 0.5, 0.6, 0.6, 0.7, 0.8, 0.8, 1.1, 1.2, 0.9, 1.1, 0.7, 0.5])\n",
    "\n",
    "# Affichage graphique des données avec incertitudes\n",
    "plt.errorbar(t, h, dh)\n",
    "plt.xlabel('Temps (s)')\n",
    "plt.ylabel('$\\log(h)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "# Ajustement avec minimisation du chi2\n",
    "params, pcov = curve_fit(expLaw, t, h, [14, 200], sigma = dh)\n",
    "# Récupération des incertitudes à partir de la matrice de covariance\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Affichage des valeurs des paramètres et des incertitudes\n",
    "a = params[0]\n",
    "tau = params[1]\n",
    "da = perr[0]\n",
    "dtau = perr[1]\n",
    "print('a =', a, '+-', da, 'cm')\n",
    "print('tau =', tau, '+-', dtau, 's')\n",
    "\n",
    "# Calcul du modèle\n",
    "t_model = np.linspace(min(t), max(t))\n",
    "h_model = expLaw(t_model, a, tau)\n",
    "\n",
    "# Représentation graphique du modèle et des données\n",
    "plt.errorbar(t, h, dh, label = 'données expérimentales')\n",
    "plt.plot(t_model, h_model, label = 'modèle')\n",
    "plt.title('Ajustement exponentiel du modèle aux données\\nMinimisation du $\\chi^2$')\n",
    "plt.xlabel(\"$t~\\mathrm{(s)}$\")\n",
    "plt.ylabel(\"$h~\\mathrm{(cm)}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
